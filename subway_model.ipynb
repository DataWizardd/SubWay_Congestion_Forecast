{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5708fd3a-2082-4e37-8fef-e882f58b8f31",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "from hyperopt import fmin, tpe, hp, Trials, STATUS_OK\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "72641f90-799e-4674-89e3-f7de903220c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = r\"C:\\Users\\james\\J_Data_Lab\\Project_subway\\data\\df_subway_prep2.csv\"\n",
    "df = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "768ced4c-8e84-45eb-a6e9-e6d7ed57fa54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5571731 entries, 0 to 5571730\n",
      "Data columns (total 49 columns):\n",
      " #   Column          Dtype  \n",
      "---  ------          -----  \n",
      " 0   년도              int64  \n",
      " 1   분기              int64  \n",
      " 2   수송연월            object \n",
      " 3   날짜              object \n",
      " 4   요일구분            object \n",
      " 5   공휴일 여부          int64  \n",
      " 6   호선명             int64  \n",
      " 7   역명              object \n",
      " 8   시간              object \n",
      " 9   승차인원            int64  \n",
      " 10  하차인원            int64  \n",
      " 11  우대권인원수          int64  \n",
      " 12  청소년인원수          int64  \n",
      " 13  기온(°C)          float64\n",
      " 14  강수량(mm)         float64\n",
      " 15  풍속(m/s)         float64\n",
      " 16  습도(%)           int64  \n",
      " 17  적설(cm)          float64\n",
      " 18  승하차인원           int64  \n",
      " 19  출입구             int64  \n",
      " 20  섬식여부            int64  \n",
      " 21  환승노선_개수         int64  \n",
      " 22  면적              float64\n",
      " 23  수송인원수           float64\n",
      " 24  환승유입인원수         float64\n",
      " 25  상선 혼잡도          float64\n",
      " 26  하선 혼잡도          float64\n",
      " 27  승강장혼잡도1         float64\n",
      " 28  승강장혼잡도2         float64\n",
      " 29  지하철요금           float64\n",
      " 30  달러 환율           float64\n",
      " 31  달러 대비 지하철요금     float64\n",
      " 32  승하차인원차          int64  \n",
      " 33  보통휘발유           float64\n",
      " 34  자동차용경유          float64\n",
      " 35  실업률(%)          float64\n",
      " 36  청년실업률(%)        float64\n",
      " 37  동행지수 순환변동치      float64\n",
      " 38  선행지수 순환변동치      float64\n",
      " 39  서울_인구(천명)       int64  \n",
      " 40  서울_인구밀도         int64  \n",
      " 41  수도권_인구(천명)      int64  \n",
      " 42  수도권_인구밀도        int64  \n",
      " 43  승하차인원 대비 서울인구   float64\n",
      " 44  승하차인원 대비 수도권인구  float64\n",
      " 45  자동차등록대수(만대)     int64  \n",
      " 46  기준금리            float64\n",
      " 47  한국CPI           float64\n",
      " 48  CPI_대비_지하철요금    float64\n",
      "dtypes: float64(25), int64(19), object(5)\n",
      "memory usage: 2.0+ GB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "877a9be8-b7ce-4c86-8b96-b2c20264b004",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 한글 폰트\n",
    "plt.rcParams['font.family'] = 'Malgun Gothic'\n",
    "plt.rcParams['axes.unicode_minus'] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ad9d9032-1d85-4508-9551-d9b12c5cca48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 전처리 함수 수정\n",
    "def preprocess_data(file_path):\n",
    "    df = pd.read_csv(file_path)\n",
    "    \n",
    "    # 결측치 0으로 대체\n",
    "    df.fillna(0, inplace=True)\n",
    "    \n",
    "    # **1호선 데이터만 선택**\n",
    "    df = df[df['호선명'] == 1].reset_index(drop=True)\n",
    "    \n",
    "    # '날짜'를 datetime으로 변환 후 숫자형으로 변환\n",
    "    df['날짜'] = pd.to_datetime(df['날짜'])\n",
    "    df['날짜_numeric'] = df['날짜'].map(pd.Timestamp.toordinal)\n",
    "    \n",
    "    # '요일구분'을 숫자형으로 변환\n",
    "    weekday_mapping = {'평일': 0, '토요일': 1, '일요일': 2}\n",
    "    df['요일구분'] = df['요일구분'].map(weekday_mapping)\n",
    "    \n",
    "    # '시간'을 숫자형으로 변환 (시간대만 추출하여 정수형으로 변환)\n",
    "    df['시간'] = df['시간'].str.split(':').str[0].astype(int)\n",
    "    \n",
    "    # '역명'을 Label Encoding\n",
    "    le_station = LabelEncoder()\n",
    "    df['역명'] = le_station.fit_transform(df['역명'])\n",
    "    \n",
    "    # '날짜'부터 시작하는 변수 선택\n",
    "    columns = df.columns.tolist()\n",
    "    start_index = columns.index('날짜')\n",
    "    selected_columns = columns[start_index:]\n",
    "    \n",
    "    # 제외할 변수 지정\n",
    "    excluded_columns = ['승하차인원', '면적', '승강장혼잡도2', '승강장혼잡도1', '날짜','년도','분기','수송연월']\n",
    "    feature_columns = [col for col in selected_columns if col not in excluded_columns]\n",
    "    \n",
    "    # 독립 변수와 종속 변수 분리\n",
    "    X = df[feature_columns]\n",
    "    y = df['승강장혼잡도1']\n",
    "    \n",
    "    # 남아있는 object 타입의 변수 처리 (Label Encoding)\n",
    "    object_cols = X.select_dtypes(include=['object']).columns\n",
    "    if len(object_cols) > 0:\n",
    "        for col in object_cols:\n",
    "            le = LabelEncoder()\n",
    "            X[col] = le.fit_transform(X[col])\n",
    "    \n",
    "    # 학습용과 검증용 데이터로 분할\n",
    "    X_train, X_val, Y_train, Y_val = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "    \n",
    "    # 스케일링\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_val_scaled = scaler.transform(X_val)\n",
    "    \n",
    "    # 결과를 딕셔너리 형태로 반환\n",
    "    data = {\n",
    "        'X_train_scaled': X_train_scaled,\n",
    "        'Y_train': Y_train,\n",
    "        'X_val_scaled': X_val_scaled,\n",
    "        'Y_val': Y_val,\n",
    "        'train_data': X_train,\n",
    "        'val_data': X_val\n",
    "    }\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "abc0708d-a90b-4fdc-8611-15e1a6dc91c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결과 시각화 함수 정의 \n",
    "def plot_results(train_data, val_data, Y_train, Y_train_pred, Y_val, Y_val_pred, model_name):\n",
    "    plt.figure(figsize=(14, 6))\n",
    "    \n",
    "    # 학습 데이터 결과\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.scatter(Y_train, Y_train_pred, alpha=0.3)\n",
    "    plt.xlabel('실제 값')\n",
    "    plt.ylabel('예측 값')\n",
    "    plt.title(f'{model_name} - 학습 데이터')\n",
    "\n",
    "    # 검증 데이터 결과\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.scatter(Y_val, Y_val_pred, alpha=0.3, color='orange')\n",
    "    plt.xlabel('실제 값')\n",
    "    plt.ylabel('예측 값')\n",
    "    plt.title(f'{model_name} - 검증 데이터')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b271b1f0-02b2-4bf8-8c76-2012948a47cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#랜덤포레스트\n",
    "def model_rf(X_train_scaled, Y_train, X_val_scaled, Y_val, max_evals=100):\n",
    "    space = {\n",
    "        'n_estimators': hp.quniform('n_estimators', 100, 300, 10),\n",
    "        'max_depth': hp.quniform('max_depth', 5, 30, 1),\n",
    "        'min_samples_split': hp.quniform('min_samples_split', 2, 10, 1),\n",
    "        'min_samples_leaf': hp.quniform('min_samples_leaf', 1, 10, 1),\n",
    "        'max_features': hp.uniform('max_features', 0.1, 1.0),\n",
    "        'bootstrap': hp.choice('bootstrap', [True, False])\n",
    "    }\n",
    "\n",
    "    def objective(space):\n",
    "        clf = RandomForestRegressor(\n",
    "            n_estimators=int(space['n_estimators']),\n",
    "            max_depth=int(space['max_depth']),\n",
    "            min_samples_split=int(space['min_samples_split']),\n",
    "            min_samples_leaf=int(space['min_samples_leaf']),\n",
    "            max_features=space['max_features'],\n",
    "            bootstrap=space['bootstrap'],\n",
    "            random_state=0\n",
    "        )\n",
    "        clf.fit(X_train_scaled, Y_train)\n",
    "        pred = clf.predict(X_val_scaled)\n",
    "        mae = mean_absolute_error(Y_val, pred)\n",
    "        return {'loss': mae, 'status': STATUS_OK}\n",
    "\n",
    "    trials = Trials()\n",
    "    best_hyperparams = fmin(fn=objective,\n",
    "                            space=space,\n",
    "                            algo=tpe.suggest,\n",
    "                            max_evals=max_evals,\n",
    "                            trials=trials)\n",
    "\n",
    "    best_model = RandomForestRegressor(\n",
    "        n_estimators=int(best_hyperparams['n_estimators']),\n",
    "        max_depth=int(best_hyperparams['max_depth']),\n",
    "        min_samples_split=int(best_hyperparams['min_samples_split']),\n",
    "        min_samples_leaf=int(best_hyperparams['min_samples_leaf']),\n",
    "        max_features=best_hyperparams['max_features'],\n",
    "        bootstrap=best_hyperparams['bootstrap'],\n",
    "        random_state=0\n",
    "    )\n",
    "\n",
    "    best_model.fit(X_train_scaled, Y_train)\n",
    "\n",
    "    Y_train_pred_best = best_model.predict(X_train_scaled)\n",
    "    train_r_squared_best = r2_score(Y_train, Y_train_pred_best)\n",
    "    train_mae_best = mean_absolute_error(Y_train, Y_train_pred_best)\n",
    "    train_mse_best = mean_squared_error(Y_train, Y_train_pred_best)\n",
    "    train_mape_best = np.mean(np.abs((Y_train - Y_train_pred_best) / Y_train)) * 100\n",
    "\n",
    "    Y_val_pred_best = best_model.predict(X_val_scaled)\n",
    "    val_r_squared_best = r2_score(Y_val, Y_val_pred_best)\n",
    "    val_mae_best = mean_absolute_error(Y_val, Y_val_pred_best)\n",
    "    val_mse_best = mean_squared_error(Y_val, Y_val_pred_best)\n",
    "    val_mape_best = np.mean(np.abs((Y_val - Y_val_pred_best) / Y_val)) * 100\n",
    "\n",
    "    results = {\n",
    "        'best_hyperparams': best_hyperparams,\n",
    "        'train_metrics': {\n",
    "            'r_squared': train_r_squared_best,\n",
    "            'mae': train_mae_best,\n",
    "            'mse': train_mse_best,\n",
    "            'mape': train_mape_best\n",
    "        },\n",
    "        'val_metrics': {\n",
    "            'r_squared': val_r_squared_best,\n",
    "            'mae': val_mae_best,\n",
    "            'mse': val_mse_best,\n",
    "            'mape': val_mape_best\n",
    "        }\n",
    "    }\n",
    "    return best_model, results\n",
    "\n",
    "#XGB\n",
    "def model_xgb(X_train_scaled, Y_train, X_val_scaled, Y_val, max_evals=100):\n",
    "    space = {\n",
    "        'n_estimators': hp.quniform('n_estimators', 100, 300, 10),\n",
    "        'max_depth': hp.quniform('max_depth', 3, 15, 1),\n",
    "        'learning_rate': hp.uniform('learning_rate', 0.01, 0.3),\n",
    "        'subsample': hp.uniform('subsample', 0.7, 1.0),\n",
    "        'colsample_bytree': hp.uniform('colsample_bytree', 0.7, 1.0),\n",
    "        'gamma': hp.uniform('gamma', 0, 0.5),\n",
    "        'reg_alpha': hp.uniform('reg_alpha', 0, 1.0),\n",
    "        'reg_lambda': hp.uniform('reg_lambda', 0, 1.0)\n",
    "    }\n",
    "\n",
    "    def objective(space):\n",
    "        clf = xgb.XGBRegressor(\n",
    "            n_estimators=int(space['n_estimators']),\n",
    "            max_depth=int(space['max_depth']),\n",
    "            learning_rate=space['learning_rate'],\n",
    "            subsample=space['subsample'],\n",
    "            colsample_bytree=space['colsample_bytree'],\n",
    "            gamma=space['gamma'],\n",
    "            reg_alpha=space['reg_alpha'],\n",
    "            reg_lambda=space['reg_lambda'],\n",
    "            random_state=0\n",
    "        )\n",
    "        clf.fit(X_train_scaled, Y_train)\n",
    "        pred = clf.predict(X_val_scaled)\n",
    "        mae = mean_absolute_error(Y_val, pred)\n",
    "        return {'loss': mae, 'status': STATUS_OK}\n",
    "\n",
    "    trials = Trials()\n",
    "    best_hyperparams = fmin(fn=objective,\n",
    "                            space=space,\n",
    "                            algo=tpe.suggest,\n",
    "                            max_evals=max_evals,\n",
    "                            trials=trials)\n",
    "\n",
    "    best_model = xgb.XGBRegressor(\n",
    "        n_estimators=int(best_hyperparams['n_estimators']),\n",
    "        max_depth=int(best_hyperparams['max_depth']),\n",
    "        learning_rate=best_hyperparams['learning_rate'],\n",
    "        subsample=best_hyperparams['subsample'],\n",
    "        colsample_bytree=best_hyperparams['colsample_bytree'],\n",
    "        gamma=best_hyperparams['gamma'],\n",
    "        reg_alpha=best_hyperparams['reg_alpha'],\n",
    "        reg_lambda=best_hyperparams['reg_lambda'],\n",
    "        random_state=0\n",
    "    )\n",
    "\n",
    "    best_model.fit(X_train_scaled, Y_train)\n",
    "\n",
    "    Y_train_pred_best = best_model.predict(X_train_scaled)\n",
    "    train_r_squared_best = r2_score(Y_train, Y_train_pred_best)\n",
    "    train_mae_best = mean_absolute_error(Y_train, Y_train_pred_best)\n",
    "    train_mse_best = mean_squared_error(Y_train, Y_train_pred_best)\n",
    "    train_mape_best = np.mean(np.abs((Y_train - Y_train_pred_best) / Y_train)) * 100\n",
    "\n",
    "    Y_val_pred_best = best_model.predict(X_val_scaled)\n",
    "    val_r_squared_best = r2_score(Y_val, Y_val_pred_best)\n",
    "    val_mae_best = mean_absolute_error(Y_val, Y_val_pred_best)\n",
    "    val_mse_best = mean_squared_error(Y_val, Y_val_pred_best)\n",
    "    val_mape_best = np.mean(np.abs((Y_val - Y_val_pred_best) / Y_val)) * 100\n",
    "\n",
    "    results = {\n",
    "        'best_hyperparams': best_hyperparams,\n",
    "        'train_metrics': {\n",
    "            'r_squared': train_r_squared_best,\n",
    "            'mae': train_mae_best,\n",
    "            'mse': train_mse_best,\n",
    "            'mape': train_mape_best\n",
    "        },\n",
    "        'val_metrics': {\n",
    "            'r_squared': val_r_squared_best,\n",
    "            'mae': val_mae_best,\n",
    "            'mse': val_mse_best,\n",
    "            'mape': val_mape_best\n",
    "        }\n",
    "    }\n",
    "    return best_model, results\n",
    "    \n",
    "# LightGBM 모델 함수 \n",
    "def model_lightgbm(X_train_scaled, Y_train, X_val_scaled, Y_val, max_evals=100):\n",
    "    space = {\n",
    "        'num_leaves': hp.quniform('num_leaves', 20, 150, 1),\n",
    "        'max_depth': hp.quniform('max_depth', 5, 30, 1),\n",
    "        'learning_rate': hp.uniform('learning_rate', 0.01, 0.3),\n",
    "        'n_estimators': hp.quniform('n_estimators', 100, 500, 10),\n",
    "        'min_child_weight': hp.quniform('min_child_weight', 1, 10, 1),\n",
    "        'subsample': hp.uniform('subsample', 0.7, 1.0),\n",
    "        'colsample_bytree': hp.uniform('colsample_bytree', 0.7, 1.0),\n",
    "        'reg_alpha': hp.uniform('reg_alpha', 0, 1.0),\n",
    "        'reg_lambda': hp.uniform('reg_lambda', 0, 1.0)\n",
    "    }\n",
    "\n",
    "    def objective(space):\n",
    "        clf = lgb.LGBMRegressor(\n",
    "            num_leaves=int(space['num_leaves']),\n",
    "            max_depth=int(space['max_depth']),\n",
    "            learning_rate=space['learning_rate'],\n",
    "            n_estimators=int(space['n_estimators']),\n",
    "            min_child_weight=space['min_child_weight'],\n",
    "            subsample=space['subsample'],\n",
    "            colsample_bytree=space['colsample_bytree'],\n",
    "            reg_alpha=space['reg_alpha'],\n",
    "            reg_lambda=space['reg_lambda'],\n",
    "            random_state=0\n",
    "        )\n",
    "        clf.fit(X_train_scaled, Y_train)\n",
    "        pred = clf.predict(X_val_scaled)\n",
    "        mae = mean_absolute_error(Y_val, pred)\n",
    "        return {'loss': mae, 'status': STATUS_OK}\n",
    "\n",
    "    trials = Trials()\n",
    "    best_hyperparams = fmin(fn=objective,\n",
    "                            space=space,\n",
    "                            algo=tpe.suggest,\n",
    "                            max_evals=max_evals,\n",
    "                            trials=trials)\n",
    "\n",
    "    best_model = lgb.LGBMRegressor(\n",
    "        num_leaves=int(best_hyperparams['num_leaves']),\n",
    "        max_depth=int(best_hyperparams['max_depth']),\n",
    "        learning_rate=best_hyperparams['learning_rate'],\n",
    "        n_estimators=int(best_hyperparams['n_estimators']),\n",
    "        min_child_weight=best_hyperparams['min_child_weight'],\n",
    "        subsample=best_hyperparams['subsample'],\n",
    "        colsample_bytree=best_hyperparams['colsample_bytree'],\n",
    "        reg_alpha=best_hyperparams['reg_alpha'],\n",
    "        reg_lambda=best_hyperparams['reg_lambda'],\n",
    "        random_state=0\n",
    "    )\n",
    "\n",
    "    best_model.fit(X_train_scaled, Y_train)\n",
    "\n",
    "    Y_train_pred_best = best_model.predict(X_train_scaled)\n",
    "    train_r_squared_best = r2_score(Y_train, Y_train_pred_best)\n",
    "    train_mae_best = mean_absolute_error(Y_train, Y_train_pred_best)\n",
    "    train_mse_best = mean_squared_error(Y_train, Y_train_pred_best)\n",
    "    train_mape_best = np.mean(np.abs((Y_train - Y_train_pred_best) / Y_train)) * 100\n",
    "\n",
    "    Y_val_pred_best = best_model.predict(X_val_scaled)\n",
    "    val_r_squared_best = r2_score(Y_val, Y_val_pred_best)\n",
    "    val_mae_best = mean_absolute_error(Y_val, Y_val_pred_best)\n",
    "    val_mse_best = mean_squared_error(Y_val, Y_val_pred_best)\n",
    "    val_mape_best = np.mean(np.abs((Y_val - Y_val_pred_best) / Y_val)) * 100\n",
    "\n",
    "    results = {\n",
    "        'best_hyperparams': best_hyperparams,\n",
    "        'train_metrics': {\n",
    "            'r_squared': train_r_squared_best,\n",
    "            'mae': train_mae_best,\n",
    "            'mse': train_mse_best,\n",
    "            'mape': train_mape_best\n",
    "        },\n",
    "        'val_metrics': {\n",
    "            'r_squared': val_r_squared_best,\n",
    "            'mae': val_mae_best,\n",
    "            'mse': val_mse_best,\n",
    "            'mape': val_mape_best\n",
    "        }\n",
    "    }\n",
    "    return best_model, results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d225b011-91f5-46c6-bafc-cad06bc7ce3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = r\"C:\\Users\\james\\J_Data_Lab\\Project_subway\\data\\df_subway_prep2.csv\"\n",
    "data = preprocess_data(file_path)\n",
    "\n",
    "X_train_scaled = data['X_train_scaled']\n",
    "Y_train = data['Y_train']\n",
    "X_val_scaled = data['X_val_scaled']\n",
    "Y_val = data['Y_val']\n",
    "train_data = data['train_data']\n",
    "val_data = data['val_data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "82d833ee-b716-4c85-af24-8ce4f8ab6285",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "--- Random Forest 모델 학습 및 평가 ---\n",
      "\n",
      "  0%|                                                                           | 0/50 [01:56<?, ?trial/s, best loss=?]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 11\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m model_name, model_func \u001b[38;5;129;01min\u001b[39;00m models\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m--- \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m 모델 학습 및 평가 ---\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 11\u001b[0m     best_model, results \u001b[38;5;241m=\u001b[39m \u001b[43mmodel_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_scaled\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_val_scaled\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_evals\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     13\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbest_hyperparams\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m results:\n\u001b[0;32m     14\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m 모델의 최적 하이퍼파라미터:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[13], line 28\u001b[0m, in \u001b[0;36mmodel_rf\u001b[1;34m(X_train_scaled, Y_train, X_val_scaled, Y_val, max_evals)\u001b[0m\n\u001b[0;32m     25\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m'\u001b[39m: mae, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstatus\u001b[39m\u001b[38;5;124m'\u001b[39m: STATUS_OK}\n\u001b[0;32m     27\u001b[0m trials \u001b[38;5;241m=\u001b[39m Trials()\n\u001b[1;32m---> 28\u001b[0m best_hyperparams \u001b[38;5;241m=\u001b[39m \u001b[43mfmin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobjective\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     29\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mspace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mspace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     30\u001b[0m \u001b[43m                        \u001b[49m\u001b[43malgo\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtpe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msuggest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     31\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mmax_evals\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_evals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     32\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mtrials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrials\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     34\u001b[0m best_model \u001b[38;5;241m=\u001b[39m RandomForestRegressor(\n\u001b[0;32m     35\u001b[0m     n_estimators\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mint\u001b[39m(best_hyperparams[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mn_estimators\u001b[39m\u001b[38;5;124m'\u001b[39m]),\n\u001b[0;32m     36\u001b[0m     max_depth\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mint\u001b[39m(best_hyperparams[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax_depth\u001b[39m\u001b[38;5;124m'\u001b[39m]),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     41\u001b[0m     random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m\n\u001b[0;32m     42\u001b[0m )\n\u001b[0;32m     44\u001b[0m best_model\u001b[38;5;241m.\u001b[39mfit(X_train_scaled, Y_train)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\my_new_env\\lib\\site-packages\\hyperopt\\fmin.py:540\u001b[0m, in \u001b[0;36mfmin\u001b[1;34m(fn, space, algo, max_evals, timeout, loss_threshold, trials, rstate, allow_trials_fmin, pass_expr_memo_ctrl, catch_eval_exceptions, verbose, return_argmin, points_to_evaluate, max_queue_len, show_progressbar, early_stop_fn, trials_save_file)\u001b[0m\n\u001b[0;32m    537\u001b[0m     fn \u001b[38;5;241m=\u001b[39m __objective_fmin_wrapper(fn)\n\u001b[0;32m    539\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m allow_trials_fmin \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(trials, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfmin\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m--> 540\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtrials\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfmin\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    541\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    542\u001b[0m \u001b[43m        \u001b[49m\u001b[43mspace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    543\u001b[0m \u001b[43m        \u001b[49m\u001b[43malgo\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43malgo\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    544\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_evals\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_evals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    545\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    546\u001b[0m \u001b[43m        \u001b[49m\u001b[43mloss_threshold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mloss_threshold\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    547\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_queue_len\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_queue_len\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    548\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrstate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrstate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    549\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpass_expr_memo_ctrl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpass_expr_memo_ctrl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    550\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    551\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcatch_eval_exceptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcatch_eval_exceptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    552\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_argmin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_argmin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    553\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshow_progressbar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_progressbar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    554\u001b[0m \u001b[43m        \u001b[49m\u001b[43mearly_stop_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mearly_stop_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    555\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrials_save_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrials_save_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    556\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    558\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m trials \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    559\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(trials_save_file):\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\my_new_env\\lib\\site-packages\\hyperopt\\base.py:671\u001b[0m, in \u001b[0;36mTrials.fmin\u001b[1;34m(self, fn, space, algo, max_evals, timeout, loss_threshold, max_queue_len, rstate, verbose, pass_expr_memo_ctrl, catch_eval_exceptions, return_argmin, show_progressbar, early_stop_fn, trials_save_file)\u001b[0m\n\u001b[0;32m    666\u001b[0m \u001b[38;5;66;03m# -- Stop-gap implementation!\u001b[39;00m\n\u001b[0;32m    667\u001b[0m \u001b[38;5;66;03m#    fmin should have been a Trials method in the first place\u001b[39;00m\n\u001b[0;32m    668\u001b[0m \u001b[38;5;66;03m#    but for now it's still sitting in another file.\u001b[39;00m\n\u001b[0;32m    669\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfmin\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m fmin\n\u001b[1;32m--> 671\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfmin\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    672\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    673\u001b[0m \u001b[43m    \u001b[49m\u001b[43mspace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    674\u001b[0m \u001b[43m    \u001b[49m\u001b[43malgo\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43malgo\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    675\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_evals\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_evals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    676\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    677\u001b[0m \u001b[43m    \u001b[49m\u001b[43mloss_threshold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mloss_threshold\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    678\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    679\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrstate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrstate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    680\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    681\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_queue_len\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_queue_len\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    682\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_trials_fmin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# -- prevent recursion\u001b[39;49;00m\n\u001b[0;32m    683\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpass_expr_memo_ctrl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpass_expr_memo_ctrl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    684\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcatch_eval_exceptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcatch_eval_exceptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    685\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_argmin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_argmin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    686\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshow_progressbar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_progressbar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    687\u001b[0m \u001b[43m    \u001b[49m\u001b[43mearly_stop_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mearly_stop_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    688\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrials_save_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrials_save_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    689\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\my_new_env\\lib\\site-packages\\hyperopt\\fmin.py:586\u001b[0m, in \u001b[0;36mfmin\u001b[1;34m(fn, space, algo, max_evals, timeout, loss_threshold, trials, rstate, allow_trials_fmin, pass_expr_memo_ctrl, catch_eval_exceptions, verbose, return_argmin, points_to_evaluate, max_queue_len, show_progressbar, early_stop_fn, trials_save_file)\u001b[0m\n\u001b[0;32m    583\u001b[0m rval\u001b[38;5;241m.\u001b[39mcatch_eval_exceptions \u001b[38;5;241m=\u001b[39m catch_eval_exceptions\n\u001b[0;32m    585\u001b[0m \u001b[38;5;66;03m# next line is where the fmin is actually executed\u001b[39;00m\n\u001b[1;32m--> 586\u001b[0m \u001b[43mrval\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexhaust\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    588\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m return_argmin:\n\u001b[0;32m    589\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(trials\u001b[38;5;241m.\u001b[39mtrials) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\my_new_env\\lib\\site-packages\\hyperopt\\fmin.py:364\u001b[0m, in \u001b[0;36mFMinIter.exhaust\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    362\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mexhaust\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    363\u001b[0m     n_done \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrials)\n\u001b[1;32m--> 364\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_evals\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mn_done\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mblock_until_done\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masynchronous\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    365\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrials\u001b[38;5;241m.\u001b[39mrefresh()\n\u001b[0;32m    366\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\my_new_env\\lib\\site-packages\\hyperopt\\fmin.py:300\u001b[0m, in \u001b[0;36mFMinIter.run\u001b[1;34m(self, N, block_until_done)\u001b[0m\n\u001b[0;32m    297\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpoll_interval_secs)\n\u001b[0;32m    298\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    299\u001b[0m     \u001b[38;5;66;03m# -- loop over trials and do the jobs directly\u001b[39;00m\n\u001b[1;32m--> 300\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mserial_evaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    302\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrials\u001b[38;5;241m.\u001b[39mrefresh()\n\u001b[0;32m    303\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrials_save_file \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\my_new_env\\lib\\site-packages\\hyperopt\\fmin.py:178\u001b[0m, in \u001b[0;36mFMinIter.serial_evaluate\u001b[1;34m(self, N)\u001b[0m\n\u001b[0;32m    176\u001b[0m ctrl \u001b[38;5;241m=\u001b[39m base\u001b[38;5;241m.\u001b[39mCtrl(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrials, current_trial\u001b[38;5;241m=\u001b[39mtrial)\n\u001b[0;32m    177\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 178\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdomain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mspec\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctrl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    179\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    180\u001b[0m     logger\u001b[38;5;241m.\u001b[39merror(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mjob exception: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mstr\u001b[39m(e))\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\my_new_env\\lib\\site-packages\\hyperopt\\base.py:892\u001b[0m, in \u001b[0;36mDomain.evaluate\u001b[1;34m(self, config, ctrl, attach_attachments)\u001b[0m\n\u001b[0;32m    883\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    884\u001b[0m     \u001b[38;5;66;03m# -- the \"work\" of evaluating `config` can be written\u001b[39;00m\n\u001b[0;32m    885\u001b[0m     \u001b[38;5;66;03m#    either into the pyll part (self.expr)\u001b[39;00m\n\u001b[0;32m    886\u001b[0m     \u001b[38;5;66;03m#    or the normal Python part (self.fn)\u001b[39;00m\n\u001b[0;32m    887\u001b[0m     pyll_rval \u001b[38;5;241m=\u001b[39m pyll\u001b[38;5;241m.\u001b[39mrec_eval(\n\u001b[0;32m    888\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexpr,\n\u001b[0;32m    889\u001b[0m         memo\u001b[38;5;241m=\u001b[39mmemo,\n\u001b[0;32m    890\u001b[0m         print_node_on_error\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrec_eval_print_node_on_error,\n\u001b[0;32m    891\u001b[0m     )\n\u001b[1;32m--> 892\u001b[0m     rval \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpyll_rval\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    894\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(rval, (\u001b[38;5;28mfloat\u001b[39m, \u001b[38;5;28mint\u001b[39m, np\u001b[38;5;241m.\u001b[39mnumber)):\n\u001b[0;32m    895\u001b[0m     dict_rval \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mfloat\u001b[39m(rval), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstatus\u001b[39m\u001b[38;5;124m\"\u001b[39m: STATUS_OK}\n",
      "Cell \u001b[1;32mIn[13], line 22\u001b[0m, in \u001b[0;36mmodel_rf.<locals>.objective\u001b[1;34m(space)\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mobjective\u001b[39m(space):\n\u001b[0;32m     13\u001b[0m     clf \u001b[38;5;241m=\u001b[39m RandomForestRegressor(\n\u001b[0;32m     14\u001b[0m         n_estimators\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mint\u001b[39m(space[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mn_estimators\u001b[39m\u001b[38;5;124m'\u001b[39m]),\n\u001b[0;32m     15\u001b[0m         max_depth\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mint\u001b[39m(space[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax_depth\u001b[39m\u001b[38;5;124m'\u001b[39m]),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     20\u001b[0m         random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m\n\u001b[0;32m     21\u001b[0m     )\n\u001b[1;32m---> 22\u001b[0m     \u001b[43mclf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_scaled\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     23\u001b[0m     pred \u001b[38;5;241m=\u001b[39m clf\u001b[38;5;241m.\u001b[39mpredict(X_val_scaled)\n\u001b[0;32m     24\u001b[0m     mae \u001b[38;5;241m=\u001b[39m mean_absolute_error(Y_val, pred)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\my_new_env\\lib\\site-packages\\sklearn\\base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1471\u001b[0m     )\n\u001b[0;32m   1472\u001b[0m ):\n\u001b[1;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\my_new_env\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:489\u001b[0m, in \u001b[0;36mBaseForest.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    478\u001b[0m trees \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    479\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_estimator(append\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, random_state\u001b[38;5;241m=\u001b[39mrandom_state)\n\u001b[0;32m    480\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_more_estimators)\n\u001b[0;32m    481\u001b[0m ]\n\u001b[0;32m    483\u001b[0m \u001b[38;5;66;03m# Parallel loop: we prefer the threading backend as the Cython code\u001b[39;00m\n\u001b[0;32m    484\u001b[0m \u001b[38;5;66;03m# for fitting the trees is internally releasing the Python GIL\u001b[39;00m\n\u001b[0;32m    485\u001b[0m \u001b[38;5;66;03m# making threading more efficient than multiprocessing in\u001b[39;00m\n\u001b[0;32m    486\u001b[0m \u001b[38;5;66;03m# that case. However, for joblib 0.12+ we respect any\u001b[39;00m\n\u001b[0;32m    487\u001b[0m \u001b[38;5;66;03m# parallel_backend contexts set at a higher level,\u001b[39;00m\n\u001b[0;32m    488\u001b[0m \u001b[38;5;66;03m# since correctness does not rely on using threads.\u001b[39;00m\n\u001b[1;32m--> 489\u001b[0m trees \u001b[38;5;241m=\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    490\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    491\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    492\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprefer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mthreads\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    493\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    494\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_parallel_build_trees\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    495\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    496\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbootstrap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    497\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    498\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    499\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrees\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    503\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclass_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    504\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_samples_bootstrap\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_samples_bootstrap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    505\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    506\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    507\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrees\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    508\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    510\u001b[0m \u001b[38;5;66;03m# Collect newly grown trees\u001b[39;00m\n\u001b[0;32m    511\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_\u001b[38;5;241m.\u001b[39mextend(trees)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\my_new_env\\lib\\site-packages\\sklearn\\utils\\parallel.py:74\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     69\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     70\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     71\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     73\u001b[0m )\n\u001b[1;32m---> 74\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\my_new_env\\lib\\site-packages\\joblib\\parallel.py:1918\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1916\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_sequential_output(iterable)\n\u001b[0;32m   1917\u001b[0m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[1;32m-> 1918\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1920\u001b[0m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[0;32m   1921\u001b[0m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[0;32m   1922\u001b[0m \u001b[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[0;32m   1923\u001b[0m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[0;32m   1924\u001b[0m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[0;32m   1925\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\my_new_env\\lib\\site-packages\\joblib\\parallel.py:1847\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1845\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_batches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1846\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m-> 1847\u001b[0m res \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1848\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_completed_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1849\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_progress()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\my_new_env\\lib\\site-packages\\sklearn\\utils\\parallel.py:136\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    134\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    135\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[1;32m--> 136\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\my_new_env\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:192\u001b[0m, in \u001b[0;36m_parallel_build_trees\u001b[1;34m(tree, bootstrap, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap, missing_values_in_feature_mask)\u001b[0m\n\u001b[0;32m    189\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m class_weight \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbalanced_subsample\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    190\u001b[0m         curr_sample_weight \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m compute_sample_weight(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbalanced\u001b[39m\u001b[38;5;124m\"\u001b[39m, y, indices\u001b[38;5;241m=\u001b[39mindices)\n\u001b[1;32m--> 192\u001b[0m     \u001b[43mtree\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    193\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    194\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    195\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcurr_sample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    196\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    197\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    198\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    199\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    200\u001b[0m     tree\u001b[38;5;241m.\u001b[39m_fit(\n\u001b[0;32m    201\u001b[0m         X,\n\u001b[0;32m    202\u001b[0m         y,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    205\u001b[0m         missing_values_in_feature_mask\u001b[38;5;241m=\u001b[39mmissing_values_in_feature_mask,\n\u001b[0;32m    206\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\my_new_env\\lib\\site-packages\\sklearn\\tree\\_classes.py:472\u001b[0m, in \u001b[0;36mBaseDecisionTree._fit\u001b[1;34m(self, X, y, sample_weight, check_input, missing_values_in_feature_mask)\u001b[0m\n\u001b[0;32m    461\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    462\u001b[0m     builder \u001b[38;5;241m=\u001b[39m BestFirstTreeBuilder(\n\u001b[0;32m    463\u001b[0m         splitter,\n\u001b[0;32m    464\u001b[0m         min_samples_split,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    469\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmin_impurity_decrease,\n\u001b[0;32m    470\u001b[0m     )\n\u001b[1;32m--> 472\u001b[0m \u001b[43mbuilder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtree_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    474\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_outputs_ \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m is_classifier(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    475\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 모델별로 학습 및 평가 수행\n",
    "models = {\n",
    "    'Random Forest': model_rf,\n",
    "    'XGBoost': model_xgb,\n",
    "    'LightGBM': model_lightgbm\n",
    "}\n",
    "\n",
    "for model_name, model_func in models.items():\n",
    "    print(f'\\n\\n--- {model_name} 모델 학습 및 평가 ---\\n')\n",
    "    \n",
    "    best_model, results = model_func(X_train_scaled, Y_train, X_val_scaled, Y_val, max_evals=50)\n",
    "    \n",
    "    if 'best_hyperparams' in results:\n",
    "        print(f\"{model_name} 모델의 최적 하이퍼파라미터:\")\n",
    "        print(results['best_hyperparams'])\n",
    "    \n",
    "    print(f'{model_name}(Train):')\n",
    "    print(f\"R-squared: {results['train_metrics']['r_squared']:.4f}\")\n",
    "    print(f\"MAE: {results['train_metrics']['mae']:.4f}\")\n",
    "    print(f\"MSE: {results['train_metrics']['mse']:.4f}\")\n",
    "    print(f\"MAPE: {results['train_metrics']['mape']:.2f}%\")\n",
    "    print()\n",
    "    print(f'{model_name}(Validation):')\n",
    "    print(f\"R-squared: {results['val_metrics']['r_squared']:.4f}\")\n",
    "    print(f\"MAE: {results['val_metrics']['mae']:.4f}\")\n",
    "    print(f\"MSE: {results['val_metrics']['mse']:.4f}\")\n",
    "    print(f\"MAPE: {results['val_metrics']['mape']:.2f}%\")\n",
    "    \n",
    "    Y_train_pred = best_model.predict(X_train_scaled)\n",
    "    Y_val_pred = best_model.predict(X_val_scaled)\n",
    "    \n",
    "    plot_results(train_data, val_data, Y_train, Y_train_pred, Y_val, Y_val_pred, model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b058bfa-6b17-48cf-80d6-baaca7445cfe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (my_new_env)",
   "language": "python",
   "name": "my_new_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
